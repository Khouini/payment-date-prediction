import pandas as pd
from prophet import Prophet
import matplotlib.pyplot as plt
import json

# Load data from JSON
with open("fake_payments.json", "r") as f:
    payments = json.load(f)

# Create DataFrame
df = pd.DataFrame(payments)

# Convert 'createdAt' to datetime
df['createdAt'] = pd.to_datetime(df['createdAt'])

# Resample and sum credit and debit amounts by month
monthly_credits = df[df['type'] == 'credit'].resample('M', on='createdAt').amount.sum().reset_index()
monthly_debits = df[df['type'] == 'debit'].resample('M', on='createdAt').amount.sum().reset_index()

# Rename columns for Prophet compatibility
monthly_credits.rename(columns={'createdAt': 'ds', 'amount': 'y_credit'}, inplace=True)
monthly_debits.rename(columns={'createdAt': 'ds', 'amount': 'y_debit'}, inplace=True)

# Merge the data on date, handling missing months
merged_data = pd.merge(monthly_credits, monthly_debits, on='ds', how='outer')
merged_data.fillna(0, inplace=True)  # Assuming no transactions occurred in missing months

# Prepare datasets for Prophet
credits_data = merged_data[['ds', 'y_credit']].rename(columns={'y_credit': 'y'})
debits_data = merged_data[['ds', 'y_debit']].rename(columns={'y_debit': 'y'})

# Initialize Prophet models for credit and debit predictions
model_credits = Prophet(yearly_seasonality=True)
model_debits = Prophet(yearly_seasonality=True)

# Fit the models
model_credits.fit(credits_data)
model_debits.fit(debits_data)

# Make future dataframes for forecasting
future_credits = model_credits.make_future_dataframe(periods=12, freq='M')
future_debits = model_debits.make_future_dataframe(periods=12, freq='M')

# Predict future credits and debits
forecast_credits = model_credits.predict(future_credits)
forecast_debits = model_debits.predict(future_debits)

# Calculate forecast balance
forecast_credits['forecast_debits'] = forecast_debits['yhat']
forecast_credits['predicted_balance'] = forecast_credits['yhat'] - forecast_credits['forecast_debits']

# Calculate actual balance from historical data
merged_data['actual_balance'] = merged_data['y_credit'] - merged_data['y_debit']

# Plotting the results
plt.figure(figsize=(10, 6))

# Plot actual balance
plt.plot(merged_data['ds'], merged_data['actual_balance'], label='Actual Balance', color='red')
print(merged_data['actual_balance'])
# Plot forecasted balance
plt.plot(forecast_credits['ds'], forecast_credits['predicted_balance'], label='Forecasted Balance', color='blue')
print(forecast_credits['predicted_balance'])

plt.title('Actual vs. Forecasted Balance')
plt.xlabel('Date')
plt.ylabel('Balance')
plt.legend()
plt.grid(True)  # Add grid for better readability
plt.show()

from sklearn.metrics import r2_score, mean_squared_error
import numpy as np

aligned_forecast = forecast_credits.set_index('ds').loc[merged_data['ds']].reset_index()

# Calculate R-squared
r_squared = r2_score(merged_data['actual_balance'], aligned_forecast['predicted_balance'])

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(merged_data['actual_balance'], aligned_forecast['predicted_balance'])

# Calculate Root Mean Squared Error (RMSE)
rmse = np.sqrt(mse)

print("R-squared:", r_squared)
print("Mean Squared Error (MSE):", mse)
print("Root Mean Squared Error (RMSE):", rmse)


# Calculate R-squared
# R-squared (RÂ²) is like a report card for your model's performance. It tells you how well the predictions match the actual data. R-squared ranges from 0 to 1, where 1 means the model perfectly predicts the data and 0 means it's no better than guessing. So, the closer R-squared is to 1, the better your model fits the data.

# Calculate Mean Squared Error (MSE)
# Mean Squared Error (MSE) is like measuring the average size of mistakes your model makes. It takes the difference between each prediction and the actual value, squares it to get rid of negative values, adds up all those squared differences, and then divides by the number of predictions. A smaller MSE means your model's predictions are closer to the actual values on average.

# Calculate Root Mean Squared Error (RMSE)
# Root Mean Squared Error (RMSE) is like the "easy-to-read" version of MSE. It's the square root of the MSE, so it gives you the average size of the errors in the same units as the original data. For example, if you're predicting prices in dollars, RMSE will tell you, on average, how many dollars your predictions are off by. Lower RMSE values indicate better performance.
